{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e197f4c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Using incubator modules: jdk.incubator.vector\n",
      "/home/wojciechku/miniconda3/envs/multi-ct/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import os\n",
    "import xml.etree.ElementTree as ET\n",
    "from pathlib import Path\n",
    "\n",
    "import ir_datasets\n",
    "import ir_measures\n",
    "from ir_measures import calc_aggregate\n",
    "from ir_measures.measures import RR, P, nDCG\n",
    "from pyserini.search.lucene import LuceneSearcher\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "84a315fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_clinical_trials_index(output_dir):\n",
    "    \"\"\"Build Lucene index from clinical trials 2021 dataset.\"\"\"\n",
    "    print(\"Building index from clinical trials 2021 dataset...\")\n",
    "\n",
    "    # Create output directory\n",
    "    Path(output_dir).mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    # Create temporary JSONL file for indexing\n",
    "    docs_file = f\"{output_dir}/docs.jsonl\"\n",
    "\n",
    "    # Load dataset\n",
    "    clinical_trials = ir_datasets.load(\"clinicaltrials/2021/trec-ct-2021\")\n",
    "\n",
    "    # save qrels to file\n",
    "    qrels_output_file = f\"{output_dir}/qrels.txt\"\n",
    "    with open(qrels_output_file, \"w\", encoding=\"utf-8\") as f:\n",
    "        for qrel in clinical_trials.qrels_iter():\n",
    "            f.write(f\"{qrel.query_id}\\t0\\t{qrel.doc_id}\\t{qrel.relevance}\\n\")\n",
    "    print(f\"Saved qrels to {qrels_output_file}\\n\")\n",
    "\n",
    "    # Write documents to JSONL format\n",
    "    print(\"Extracting documents...\")\n",
    "    doc_count = 0\n",
    "    with open(docs_file, \"w\", encoding=\"utf-8\") as f:\n",
    "        for doc in clinical_trials.docs_iter():\n",
    "            # Create document in Pyserini format\n",
    "            doc_dict = {\n",
    "                \"id\": doc.doc_id,\n",
    "                \"contents\": f\"{doc.title} {doc.condition} {doc.summary} {doc.detailed_description} {doc.eligibility}\",\n",
    "            }\n",
    "            f.write(json.dumps(doc_dict) + \"\\n\")\n",
    "            doc_count += 1\n",
    "            if doc_count % 10000 == 0:\n",
    "                print(f\"  Processed {doc_count} documents...\")\n",
    "\n",
    "    print(f\"Total documents: {doc_count}\")\n",
    "\n",
    "    # Build index using Pyserini\n",
    "    print(\"Building Lucene index...\")\n",
    "    cmd = f\"python -m pyserini.index.lucene \\\n",
    "      --collection JsonCollection \\\n",
    "      --input {output_dir} \\\n",
    "      --index {output_dir}/index \\\n",
    "      --generator DefaultLuceneDocumentGenerator \\\n",
    "      --threads 4 \\\n",
    "      --storePositions --storeDocvectors --storeRaw\"\n",
    "\n",
    "    os.system(cmd)\n",
    "\n",
    "    print(f\"✅ Index built successfully at {output_dir}/index\\n\")\n",
    "    return f\"{output_dir}/index\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "307facec",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_topics_from_file(topic_file):\n",
    "    \"\"\"Load topics from XML file, extracting text directly from <topic> elements.\"\"\"\n",
    "    topics = {}\n",
    "    tree = ET.parse(topic_file)\n",
    "    root = tree.getroot()\n",
    "\n",
    "    for topic in root.findall(\"topic\"):\n",
    "        topic_id = topic.get(\"number\")\n",
    "        # Get all text inside <topic>, including nested elements\n",
    "        text_content = \"\".join(topic.itertext()).strip()\n",
    "        topics[topic_id] = {\"title\": text_content}\n",
    "\n",
    "    return topics\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "12e3d87c",
   "metadata": {},
   "outputs": [],
   "source": [
    "topic_files = {\n",
    "    \"original\": [\n",
    "        \"../topics/topics2021_en.xml\",\n",
    "        \"../topics/topics2021_el.xml\",\n",
    "        \"../topics/topics2021_es.xml\",\n",
    "        \"../topics/topics2021_eu.xml\",\n",
    "        \"../topics/topics2021_tr.xml\",\n",
    "        \"../topics/topics2021_pl.xml\",\n",
    "        \"../topics/topics2021_bn.xml\",\n",
    "        \"../topics/topics2021_it.xml\",\n",
    "    ],\n",
    "    \"backtranslated\": [\n",
    "        \"../topics_src_to_eng/topics_from_ben_Beng.xml\",\n",
    "        \"../topics_src_to_eng/topics_from_ell_Grek.xml\",\n",
    "        \"../topics_src_to_eng/topics_from_eus_Latn.xml\",\n",
    "        \"../topics_src_to_eng/topics_from_ita_Latn.xml\",\n",
    "        \"../topics_src_to_eng/topics_from_pol_Latn.xml\",\n",
    "        \"../topics_src_to_eng/topics_from_spa_Latn.xml\",\n",
    "        \"../topics_src_to_eng/topics_from_tur_Latn.xml\",\n",
    "    ],\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0ddfc9ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using existing index at tmp/indexes/clinical_trials_2021/index\n",
      "\n"
     ]
    }
   ],
   "source": [
    "output_dir = \"tmp/indexes/clinical_trials_2021\"\n",
    "index_path = f\"{output_dir}/index\"\n",
    "if not os.path.exists(index_path):\n",
    "    index_path = build_clinical_trials_index(output_dir=output_dir)\n",
    "else:\n",
    "    print(f\"Using existing index at {index_path}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e0b72bbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "qrels = ir_datasets.load(\"clinicaltrials/2021/trec-ct-2021\").qrels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "16c35a2d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Feb 12, 2026 8:51:56 PM org.apache.lucene.store.MemorySegmentIndexInputProvider <init>\n",
      "INFO: Using MemorySegmentIndexInput with Java 21; to disable start with -Dorg.apache.lucene.store.MMapDirectory.enableMemorySegments=false\n"
     ]
    }
   ],
   "source": [
    "# Initialize searcher with our custom index\n",
    "searcher = LuceneSearcher(index_path)\n",
    "searcher.set_bm25(0.9, 0.4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c8d6788f",
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics_eval = [\n",
    "    nDCG @ 10,\n",
    "    RR(rel=2),\n",
    "    P(rel=2) @ 10,\n",
    "    nDCG @ 5,\n",
    "    nDCG @ 1000,\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2679a210",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "Processing: ../topics/topics2021_en.xml (Language: en)\n",
      "============================================================\n",
      "Loaded 75 topics\n"
     ]
    }
   ],
   "source": [
    "results_dict = {}\n",
    "for category, files in topic_files.items():\n",
    "    for topic_file in files:\n",
    "        lang = topic_file.split(\"_\")[-1].replace(\".xml\", \"\")\n",
    "        print(f\"{'=' * 60}\")\n",
    "        print(f\"Processing: {topic_file} (Language: {lang})\")\n",
    "        print(f\"{'=' * 60}\")\n",
    "\n",
    "        # Load topics\n",
    "        try:\n",
    "            topics = load_topics_from_file(f\"{os.getcwd()}/{topic_file}\")\n",
    "            print(f\"Loaded {len(topics)} topics\")\n",
    "        except Exception as e:\n",
    "            print(f\"❌ Error loading topics: {e}\\n\")\n",
    "            continue\n",
    "\n",
    "        # Run retrieval\n",
    "        all_results = []\n",
    "        topics_with_results = 0\n",
    "\n",
    "        for topic_id, topic in topics.items():\n",
    "            try:\n",
    "                hits = searcher.search(topic[\"title\"], k=1000)\n",
    "                if hits:\n",
    "                    topics_with_results += 1\n",
    "                for rank, hit in enumerate(hits):\n",
    "                    all_results.append(\n",
    "                        {\n",
    "                            \"query_id\": str(topic_id),\n",
    "                            \"doc_id\": hit.docid,\n",
    "                            \"score\": hit.score,\n",
    "                        }\n",
    "                    )\n",
    "            except Exception as e:\n",
    "                print(f\"⚠️  Error searching for topic {topic_id}: {e}\")\n",
    "                continue\n",
    "\n",
    "        print(f\"Retrieved results for {topics_with_results}/{len(topics)} topics\")\n",
    "        print(f\"Total results: {len(all_results)}\")\n",
    "\n",
    "        # save run to file\n",
    "        run_output_file = f\"tmp/runs/bm25_clinical_trials_2021_{lang}.tsv\"\n",
    "        os.makedirs(\"tmp/runs\", exist_ok=True)\n",
    "        with open(run_output_file, \"w\", encoding=\"utf-8\") as f:\n",
    "            for r in all_results:\n",
    "                f.write(\n",
    "                    f\"{r['query_id']}\\tQ0\\t{r['doc_id']}\\t0\\t{r['score']}\\tBM25\\n\"\n",
    "                )\n",
    "        print(f\"Saved run to {run_output_file}\")\n",
    "\n",
    "        if not all_results:\n",
    "            print(f\"❌ No results found for {topic_file}\\n\")\n",
    "            continue\n",
    "\n",
    "        run_namedtuples = ir_measures.read_trec_run(\n",
    "            [(r[\"query_id\"], r[\"doc_id\"], r[\"score\"]) for r in all_results]\n",
    "        )\n",
    "        run = {}\n",
    "        for r in all_results:\n",
    "            run[(r[\"query_id\"], r[\"doc_id\"])] = r[\"score\"]\n",
    "\n",
    "        run = ir_measures.read_trec_run(run_output_file)\n",
    "\n",
    "        metrics = calc_aggregate(metrics_eval, qrels, run)\n",
    "\n",
    "        print(\"Evaluation Results:\")\n",
    "        for measure, value in metrics.items():\n",
    "            print(f\"  {measure}: {value:.4f}\")\n",
    "        print(\"\\n\")\n",
    "\n",
    "        results_dict[f\"{lang}_{category}\"] = metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87ee5644",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df = pd.DataFrame.from_dict(results_dict, orient=\"index\")\n",
    "print(results_df)\n",
    "print(results_df.sort_index())\n",
    "\n",
    "results_df.to_csv(\n",
    "    \"tmp/results/bm25_clinical_trials_2021_results.csv\"\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "multi-ct",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
